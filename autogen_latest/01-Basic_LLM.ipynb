{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Run a script to interact with chatGPT \n",
    "\n",
    "Now that we have a python environment equipped to communicate with OpenAI, letâ€™s interact with ChatGPT from it! \n",
    "Let's first import the `openai` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "We are now going to create a `client` object that will be used to connect with OpenAI. We're going to use our OpenAI API key to point toward our OpenAI account and use our credit, the connection will otherwise be refused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-07-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_HOST\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "If your API key is valid, you should not get any error messages. \n",
    "\n",
    "Next, we are going to use a basic command from the OpenAI command to basically chat with chatGPT3.5-turbo. We'll use chatGPT4 in this class, but the cost of 3.5 is much cheaper, so whenever we don't really need the performance of 4, we'll rely on 3.5. \n",
    "\n",
    "## The system prompt\n",
    "\n",
    "An important difference with how you use chatGPT on your browser is that we'll specify a `system prompt` message.\n",
    "\n",
    "The `system prompt` basically asks chatGPT to adopt a certain role for the following conversation. \n",
    "We specify the system prompt with: `\"role\": \"system\"`. \n",
    "\n",
    "We then send a request using `\"role\": \"user\"`.\n",
    "\n",
    "## Sending our first request\n",
    "\n",
    "Let's ask chatGPT3.5 to answer a message while playing a specifc role, we'll use a standard example here.\n",
    "\n",
    "The **system prompt** is: \"*You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.*\";  \n",
    "And the **message** is: \"*Compose a poem that explains the concept of recursion in programming.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "       {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n",
    "    ]) \n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "If we don't get any error message, this means that the request went well and that we can now display its result. The result will be stored in the `choices` field of the `completion` object. We can display it using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "So we were just able to interact with OpenAI's chatGPT from python! This is the first step necessary to build AI apps that rely on agents!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
