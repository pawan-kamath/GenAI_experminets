{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, CodeExecutorAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.teams import SelectorGroupChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-11-20\",\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_HOST\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "code_assistant = AssistantAgent(\n",
    "        name=\"code_assistant\",\n",
    "        system_message=\"You are a helpful assistant. Write all code in python and .sh whenever necessary. You are good at debugging code. Your job while debugging is to look at multiple possible options of solving the complex task at hand.\"\n",
    "                        \"You break down the task into smaller parts and solve them one by one. You are also good at writing code snippets and explaining them to the user.\"\n",
    "                        \"When asked to create the plot for any of the tasks always save it in a file with the extension .png and reply back with the file name.\"\n",
    "                        \"Reply only 'TERMINATE' if the task is done.\",\n",
    "        description=\"An agent that helps in debugging code and writing code snippets.\",\n",
    "        model_client=model_client,\n",
    "    )\n",
    "\n",
    "code_executor = CodeExecutorAgent(\n",
    "    name=\"code_executor\",\n",
    "    code_executor=LocalCommandLineCodeExecutor(work_dir=\"coding\"),\n",
    ")\n",
    "\n",
    "planning_agent = AssistantAgent(\n",
    "    name=\"planning_agent\",\n",
    "    description=\"An agent for planning tasks, this agent should be the first to engage when given a new task.\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"\"\"\n",
    "    You are a planning agent.\n",
    "    Your job is to break down complex tasks into smaller, manageable subtasks.\n",
    "    Your team members are:\n",
    "        code_assistant: Helps in debugging code and writing code snippets.\n",
    "        code_executor: Executes the code snippets and debugging the code.\n",
    "\n",
    "    You only plan and delegate tasks - you do not execute them yourself.\n",
    "\n",
    "    When assigning tasks, use this format:\n",
    "    1. <agent> : <task>\n",
    "\n",
    "    After all tasks are complete, summarize the findings and end with \"TERMINATE\".\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "# The termination condition is a combination of text termination and max message termination, either of which will cause the chat to terminate.\n",
    "termination = TextMentionTermination(\"TERMINATE\") | MaxMessageTermination(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_agent.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'planning_agent': planning_agent.description, 'code_assistant': code_assistant.description, 'code_executor': code_executor.description}\n",
    "history = []\n",
    "participants = ['planning_agent', 'code_assistant', 'code_executor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_prompt = \"\"\"Select an agent to perform task.\n",
    "\n",
    "{roles}\n",
    "\n",
    "Current conversation context:\n",
    "{history}\n",
    "\n",
    "Read the above conversation, then select an agent from {participants} to perform the next task.\n",
    "Make sure the planner agent has assigned tasks before other agents start working.\n",
    "Only select one agent.\n",
    "\"\"\"\n",
    "\n",
    "text_mention_termination = TextMentionTermination(\"TERMINATE\")\n",
    "max_messages_termination = MaxMessageTermination(max_messages=25)\n",
    "termination = text_mention_termination | max_messages_termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The group chat will alternate between the assistant and the code executor.\n",
    "group_chat = SelectorGroupChat(\n",
    "    [planning_agent, code_assistant, code_executor], \n",
    "    termination_condition=termination,\n",
    "    selector_prompt=selector_prompt,\n",
    "    allow_repeated_speaker=True,\n",
    "    \n",
    "    model_client=model_client,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Can you plot the stock price for AMD vs NVDA for the last 6 months? Also mark the date on the x-axis and the stock price on the y-axis. Save the plot as a .png file and reply back with the file name.\"\n",
    "\n",
    "\n",
    "# `run_stream` returns an async generator to stream the intermediate messages.\n",
    "stream = group_chat.run_stream(task=task)\n",
    "# `Console` is a simple UI to display the stream.\n",
    "\n",
    "# async for message in stream:\n",
    "#     history.append(message)\n",
    "#     print(message)\n",
    "\n",
    "await Console(stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
